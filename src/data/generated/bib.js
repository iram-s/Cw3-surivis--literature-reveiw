const generatedBibEntries = {
    "CSCI2020Simplifying": {
        "abstract": "Today, video games are a multi-billion-dollar industry, continuously evolving through the incorporation of new technologies and innovative design. However, current video game software content creation requires extensive and often-times ambiguous planning phases for developing aesthetics, online capabilities, and gameplay mechanics. Design elements can vary significantly relative to the expertise of artists, designers, budget, and overall game engine/software features and capabilities. Game development processes are often extensively long coding sessions, usually involving a highly iterative creative process, where user requirements are rarely provided. Therefore, we propose significantly simplifying game design and development with novel Artificial Cognition Architecture real-time scalability and dynamic emotion core. Rather than utilizing more static emotion state weighting emotion engines (e.g. ExAI), we leverage significant ACA research in successful implementation of analog neural learning bots with Maslowan objective function algorithms. We also leverage AI- based Artificial Psychology software which utilizes ACA\u2019s fine grained self-evolving emotion modeling in humanistic avatar patients for Psychologist training. An ACA common cognitive core provides the gaming industry with wider applications across video game genres. A modular, scalable, and cognitive emotion game architecture implements Non-Playable Character (NPC) learning and self-evolution. ACA models NPC\u2019s with fine grained emotions, providing interactive dynamic personality traits for a more realistic game environment and enables NPC self-evolution under the influence of both other NPC\u2019s and players. Furthermore, we explore current video game design engine architecture (e.g. Unity, Unreal Engine) and propose an ACA integration approach. We apply artificial cognition and emotion intelligence modeling to engender video games with more distinct, realistic consumer gaming experiences, while simultaneously minimizing software gaming development efforts and costs.",
        "author": "John N. Carbone,James Crowder, Ryan A. Carbone",
        "doi": "10.1109/CSCI51800.2020.00085",
        "publisher": "IEEE",
        "title": "Radically Simplifying Game Engines: AI Emotions & Game Self-Evolution",
        "type": "article",
        "year": "2020"
    },
    "EDTree2016": {
        "abstract": "Immersion and interactivity are a major focus when creat- ing gaming applications, as technology has improved and enabled the creation of larger and more detailed virtual environments the need for more engaging NPCs (non-playable characters) is also required. Many games utilise a form of dialogue tree when conversing with characters within a gaming application, allowing the user to choose their question- s/responses. While this method does provide a dynamic conversation system, it is quite a one-sided level of interactivity with the NPC simply responding to the current question without it affecting the conversation on a whole. We present a novel dialogue system that explores the emo- tional state of the NPC to provide a more complex form of dialogue tree, termed EDTree (Emotional Dialogue Tree). Based on user actions, the interactions between the user and the NPC are enriched by the emo- tional state of the NPC. Utilising this system will provide an immersive experience based around improved believability of virtual characters. To demonstrate the effectiveness of our approach, we show an example of a training system that explores the use of gaming technology and the proposed EDTree.",
        "author": "Jay Collins, William Hisrt, Wen Tang, Colin Luu, Peter Smith, Andrew Watson, and Reza Sahandi",
        "doi": "10.1007/978-3-319-40259-8_7",
        "title": "EDTree: Emotional Dialogue Trees for Game Based Training",
        "type": "incollection",
        "year": "2016"
    },
    "Empowering2023Metaverse": {
        "abstract": "This paper aims to motivate the development of the metaverse by highlighting the potential of artificial-intelligence- generated content (AIGC) for the metaverse. We present the first literature review on AIGC in the metaverse with state-of-the- art research classified into 5 key application areas (avatars and Non-player Characters (NPCs), content creation, virtual world generation, automatic digital twin, and personalization). Having noticed a notable gap in research through our review, we propose ways in which state-of-the-art generative AI can be applied to the metaverse. Additionally, we offer a roadmap for future research with related ethical implications.",
        "author": "Hua Xuan Qin , Pan Hui",
        "doi": "10.1109/ICDCSW60045.2023.00022",
        "journal": "2023 IEEE International Conference on Distributed Computing Systems Workshops (ICDCSW)",
        "publisher": "IEEE",
        "title": "Empowering the Metaverse with Generative AI: Survey and Future Directions",
        "type": "article",
        "year": "2023"
    },
    "abraham2010ai": {
        "abstract": "There is a long tradition of developing games in which the difficulty level is dynamically adapted to the perfor- mance of human players. However, there has been less work on the creation of game systems that perform dynamic team-mate adaption \u2013 and even less on developing team-mate NPCs (Non Player Characters) that adaptively support players in the face of opponents that adaptively increase the difficulty for the player. This paper is based on preliminary research to identify the key elements involved in developing \u201cbuddy\u201d NPC team-mates that dynamically adapt to the needs and behaviors of human players while cooperating to compete against adaptive AI opponents. We discuss the computational and design challenges involved in developing such agents in the context of a simple test game called Capture the Gunner (CTG). The main contributions of the paper include: a proposed vocabulary and framework for under- standing/modeling team-mate systems with adaptive difficulty, a particular technique for adaptive team-mate cooperation in the face of an adaptive opponent, and the identification of several significant new issues that arise in the process of developing computer games that involve adaptive NPC team-mates that cooperate with the player in the face of adaptive opponents",
        "author": "Aswin Thomas Abraham and Kevin McGee",
        "doi": "10.1109/ITW.2010.5593326",
        "publisher": "IEEE",
        "title": "AI for dynamic teammate adaptation in games",
        "type": "article",
        "year": "2010"
    },
    "buongiorno2024pangea": {
        "abstract": "This research introduces Procedural Artificial Nar- rative using Generative AI (PANGeA), a structured approach for leveraging large language models (LLMs), guided by a game designer\u2019s high-level criteria, to generate narrative content for turn-based role-playing video games (RPGs). Distinct from prior applications of LLMs used for video game design, PANGeA innovates by not only generating game level data (which includes, but is not limited to, setting, key items, and non-playable characters (NPCs)), but by also fostering dynamic, free-form interactions between the player and the environment that align with the procedural game narrative. The NPCs generated by PANGeA are personality-biased and express traits from the Big 5 Personality Model in their generated responses. PANGeA addresses challenges behind ingesting free-form text input, which can prompt LLM responses beyond the scope of the game narrative. It does so with a novel validation system that uses the LLM\u2019s intelligence to evaluate text input and align generated responses with the unfolding narrative. Making these interactions possible, PANGeA is supported by a server that hosts a custom memory system and supplies context for augmenting generated responses thus aligning them with the procedural narrative. For its broad application, the server has a REST interface enabling any game engine to integrate directly with PANGeA, as well as an LLM interface adaptable with local LLMs, or private ones such as OpenAI\u2019s models. PANGeA\u2019s ability to foster dynamic narrative generation by aligning responses with the procedural narrative is demonstrated through an empirical study and ablation test of two versions of a demo game. These are, a custom, browser-based GPT and a Unity demo. As the results show, PANGeA holds potential to assist game designers in using LLMs to generate narrative-consistent content even when provided varied and unpredictable, free-form text input.",
        "author": "Steph Buongiorno and Lawrence Jake Klinkert and Tanishq Chawla and Zixin Zhuang and Corey Clark",
        "doi": "10.48550/arXiv.2404.19721",
        "publisher": "arXiv",
        "title": "PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games",
        "type": "article",
        "year": "2024"
    },
    "freiknecht2020procedural": {
        "abstract": "In this paper we introduce an architecture, an implementation and an evaluation of a system for the automatic creation of interactive stories for games. Our goal is to algorithmically create a branched story for the entire game; in each game run a different variant is generated. The architecture uses natural language processing (NLP) to generate meaningful stories. For NLP we use a statistical language model based on a neural network (Generative Pretrained Transformer, GPT-2). The basic architecture generates stories with too many characters which tend to get incoherent for longer texts, so we add a component restricting the number of persons and improving the consistency. The system is initialized with a hand- written game introduction that defines the main characters and the inventory; it also sets the goals for the game. From that text the remainder of the game story is generated algorithmically. We have fully implemented our system, and we report initial, encouraging experimental results. ,",
        "author": "Jonas Freiknecht and Wolfgang Effelsberg",
        "doi": "10.1145/3402942.3409599",
        "publisher": "ACM",
        "title": "Procedural Generation of Interactive Stories using Language Models",
        "type": "article",
        "year": "2020"
    },
    "hasani2021immersive": {
        "abstract": "Non-Player Character (NPC) is one of the important elements in the game, because NPCs can liven up the atmosphere in the game by means of intense interaction with players with various functions. This has an impact on the game experience which is more immersive than the game being played. This study provides an overview so that NPCs are able to have dynamic dialogue with players, and this study also discusses chatbots as a communication technology that is currently emerging and its impact when combined with NPC. ,",
        "author": "Muhammad Fikri Hasani and Yogi Udjaja",
        "doi": "10.1109/ICCSAI53272.2021.96097",
        "publisher": "IEEE",
        "title": "Immersive Experience with Non-Player Characters Dynamic Dialogue",
        "type": "article",
        "year": "2021"
    },
    "kumaran2023scenecraft": {
        "abstract": "Creating engaging interactive story-based experiences dy- namically responding to individual player choices poses sig- nificant challenges for narrative-centered games. Recent ad- vances in pre-trained large language models (LLMs) have the potential to revolutionize procedural content generation for narrative-centered games. Historically, interactive narra- tive generation has specified pivotal events in the storyline, often utilizing planning-based approaches toward achieving narrative coherence and maintaining the story arc. However, manual authorship is typically used to create detail and vari- ety in non-player character (NPC) interaction to specify and instantiate plot events. This paper proposes SCENECRAFT, a narrative scene generation framework that automates NPC interaction crucial to unfolding plot events. SCENECRAFT in- terprets natural language instructions about scene objectives, NPC traits, location, and narrative variations. It then employs large language models to generate game scenes aligned with authorial intent. It generates branching conversation paths that adapt to player choices while adhering to the author\u2019s interaction goals. LLMs generate interaction scripts, seman- tically extract character emotions and gestures to align with the script, and convert dialogues into a game scripting lan- guage. The generated script can then be played utilizing an existing narrative-centered game framework. Through empir- ical evaluation using automated and human assessments, we demonstrate SCENECRAFT\u2019s effectiveness in creating narra- tive experiences based on creativity, adaptability, and align- ment with intended author instructions. ,",
        "author": "Vikram Kumaran and Jonathan Rowe and Bradford Mott and James Lester",
        "doi": "10.1609/aiide.v19i1.27504",
        "publisher": "AAAI Press",
        "title": "SceneCraft: Automating Interactive Narrative Scene Generation in Digital Games with Large Language Models",
        "type": "article",
        "year": "2023"
    },
    "park2023generative": {
        "abstract": "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and refect on days past as they plan the next day. To enable generative agents, we describe an architec- ture that extends a large language model to store a complete record of the agent\u2019s experiences using natural language, synthesize those memories over time into higher-level refections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-fve agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behav- iors. For example, starting with only a single user-specifed notion that one agent wants to throw a Valentine\u2019s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture\u2014observation, planning, and refection\u2014each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior",
        "author": "Joon Sung Park and Joseph O'Brien and Carrie Jun Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein",
        "doi": "10.1145/3586183.3606763",
        "publisher": "ACM",
        "title": "Generative Agents: Interactive Simulacra of Human Behavior",
        "type": "article",
        "year": "2023"
    },
    "zheng2024memoryrepository": {
        "abstract": "Since the release of ChatGPT, large language models (LLMs) have played a huge role in various industries. In the field of games, we have used LLMs to act as intelligent AI NPC, which makes NPCs more intelligent. However, there is still an obvious obstacle -the LLMs lacks long-term memory and human- like memory mechanism. This flawed memory mechanism prevents NPCs from Long-term interaction and humanized memory based on conversation records. Recognizing the necessity of long-term memory and humanized memory, we proposed MemoryRepository, a memory mechanism for LLMs specifically used in the AI NPC field.MemoryRepository enables the model to have short-term memory and long- term memory. Short-term memory is more detailed and full, while long-term memory are more concise and partial. MemoryRepository is inspired by human memory and forgetting mechanisms. This mechanism allows AI NPCs to forget and summarize past conversation records, thereby providing long-term interaction capabilities. More importantly, this process of forgetting and summarizing the details of short-term memory into general long-term memories makes NPCs more human-like. MemoryRepository is versatile and can adapt to closed source models such as ChatGPT and open source models such as ChatGLM. To Intuitively verify the effectiveness of MemoryRepository in the field of AI NPC, we created an example in which all NPCs are represented by LLMs adapted to MemoryRepository. The example shows that by embedding LLM in MemoryRepository and fine-tuning NPCs character dialogue data, AI NPC can conduct better long-term conversations and appear more human-like during the interaction process. To validate the effectiveness of MemoryRepository, one hundred pieces of NPCs dialogue data were created and then quantitatively analyzed through evaluation indicators. The analysis results show that NPCs equipped with MemoryRepository can summarize and forget past memories, which enables it to have the ability to hold long-term conversations and conduct more human-like conversations.",
        "author": "Shijie Zheng and Keith He and Le Yang and Jie Xiong",
        "doi": "10.1109/ACCESS.2024.3393485",
        "publisher": "IEEE",
        "title": "MemoryRepository for AI NPC",
        "type": "article",
        "year": "2024"
    }
};